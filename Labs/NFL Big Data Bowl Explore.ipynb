{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc5dc75-2c98-471e-a554-2c3329e1eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NFL Big Data Bowl Mini Lab: \n",
    "\n",
    "#In week 1 of the 2023 season, how far is the defender from the receiver in catch and incomplete scenarios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75250ff1-c04a-4cec-a657-ff312b49d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------STEP 1: Getting Setup----------- \n",
    "#os, glob, json, pathlib are all Python utility modules, not analysis tools per se.\n",
    "#They’re mostly used to load, find, and organize your Big Data Bowl files before you start analysis.\n",
    "#pandas allows us to see raw data as structured tables \n",
    "#numpy allows for fast methematical computation \n",
    "\n",
    "import os, glob, json, pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "385905ee-77fb-4894-9a6c-277618d87249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/kaggle/kaggle.json'\n",
      "Kaggle API 1.7.4.5\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/kaggle/kaggle.json'\n",
      "Next Page Token = CfDJ8IaGWDgvvrBFtGGva9hUIY78wPvqm5xVYG6iaKymUz5SDr7L8toFyMO2T3a0L7NE4Jg9Dz0KPUtrEsp-2NwLPPc\n",
      "name                                                                                    size  creationDate                \n",
      "--------------------------------------------------------------------------------  ----------  --------------------------  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w01.csv     48950314  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w02.csv     49485029  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w03.csv     51062128  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w04.csv     46685806  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w05.csv     43574971  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w06.csv     46320079  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w07.csv     39972688  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w08.csv     48114622  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w09.csv     43224522  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w10.csv     44660215  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w11.csv     41687928  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w12.csv     50591754  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w13.csv     40083483  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w14.csv     48010868  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w15.csv     48234805  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w16.csv     54152852  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w17.csv     47524865  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/input_2023_w18.csv     43583927  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/output_2023_w01.csv     1149693  2025-09-23 18:36:28.263000  \n",
      "114239_nfl_competition_files_published_analytics_final/train/output_2023_w02.csv     1151878  2025-09-23 18:36:28.263000  \n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/kaggle/kaggle.json'\n",
      "Downloading nfl-big-data-bowl-2026-analytics.zip to data\n",
      " 86%|██████████████████████████████████▌     | 89.0M/103M [00:00<00:00, 931MB/s]\n",
      "100%|█████████████████████████████████████████| 103M/103M [00:00<00:00, 932MB/s]\n"
     ]
    }
   ],
   "source": [
    "#-----------STEP 2: Create your Kaggle API and get the input/output data----------------\n",
    "\n",
    "#Download the kaggle json from your Kaggle account\n",
    "#Go to https://www.kaggle.com/\n",
    "#Click your profile icon (top-right) → choose “Settings.”\n",
    "#Scroll to the section “API.”\n",
    "#Click the blue button “Create New API Token.”\n",
    "#Kaggle downloads a file automatically called kaggle.json (it might go into your Downloads folder).\n",
    "#I put mine in a folder entitled .kaggle on my Desktop. Do the same if you want to follow the code explicitly. \n",
    "\n",
    "cfg_dir = r\"/Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/kaggle\"\n",
    "# Point Kaggle to this folder and test to ensure you have access. If you are error free, you are good to go! \n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = cfg_dir\n",
    "\n",
    "# The next command prints the current version of the Kaggle command-line tool.\n",
    "# If you see something like \"Kaggle API 1.x.x\", it’s working.\n",
    "# If you see \"command not found\", you may need to install Kaggle (`pip install kaggle`)\n",
    "!kaggle --version\n",
    "\n",
    "# This lists all files available in the NFL Big Data Bowl 2026 competition.\n",
    "# If your API key is correct, you'll see a list of CSV and ZIP files.\n",
    "# If you see \"401: Unauthorized\", your kaggle.json file isn’t linked correctly.\n",
    "!kaggle competitions files -c nfl-big-data-bowl-2026-analytics\n",
    "\n",
    "# This command downloads all competition files into a folder called \"data\"\n",
    "# inside your current working directory.\n",
    "# The \"-p data\" flag means “put the files into the ‘data’ folder”.\n",
    "# If \"data\" doesn’t exist, it will be created automatically.\n",
    "!kaggle competitions download -c nfl-big-data-bowl-2026-analytics -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a43deef7-7c3e-4049-a785-8e4a19c6d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file found at: /Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/data/input_2023_w01.csv\n",
      "Output file found at: /Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/data/output_2023_w01.csv\n"
     ]
    }
   ],
   "source": [
    "# Universal way to locate the training data folder in which you just saved your kaggle information \n",
    "from pathlib import Path\n",
    "\n",
    "# Start in the folder where Kaggle downloads files\n",
    "data_dir = Path(\"data\")\n",
    "\n",
    "# Automatically find the \"train\" subfolder no matter what its parent folder is called\n",
    "train_path = Path(\"/Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/data\")\n",
    "\n",
    "# Build file paths\n",
    "input_file = train_path / \"input_2023_w01.csv\"\n",
    "output_file = train_path / \"output_2023_w01.csv\"\n",
    "\n",
    "print(\"Input file found at:\", input_file)\n",
    "print(\"Output file found at:\", output_file)\n",
    "\n",
    "data_path = Path(\"/Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/data/*train*\")\n",
    "\n",
    "# Load week 1 files\n",
    "input_file = os.path.join(data_path, \"input_2023_w01.csv\")\n",
    "output_file = os.path.join(data_path, \"output_2023_w01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16e9885a-5899-4ab4-83a4-0272464415da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/data/*train*/input_2023_w01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read a sample and the shape of the data you have created \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_file)\n\u001b[1;32m      3\u001b[0m output_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(output_file)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/grantstarnes/Desktop/IUI Grad/TESM-S 501/Lab10-15/data/*train*/input_2023_w01.csv'"
     ]
    }
   ],
   "source": [
    "# Read a sample and the shape of the data you have created \n",
    "input_df = pd.read_csv(input_file)\n",
    "output_df = pd.read_csv(output_file)\n",
    "\n",
    "print(f\"Rows: {input_df.shape[0]:,}, Columns: {input_df.shape[1]:,}\")\n",
    "print(\"Columns:\", list(input_df.columns[:12]), \"...\")  # show first 12 columns\n",
    "print(f\"Rows: {output_df.shape[0]:,}, Columns: {output_df.shape[1]:,}\")\n",
    "print(\"Columns:\", list(output_df.columns[:12]), \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "173bd6b4-54a7-43ed-b393-b83da4edda5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lwanless\\AppData\\Local\\Temp\\1\\ipykernel_11648\\2736090475.py:27: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  supp = pd.read_csv(supp_path)          # loads a comma-separated text file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>game_date</th>\n",
       "      <th>game_time_eastern</th>\n",
       "      <th>home_team_abbr</th>\n",
       "      <th>visitor_team_abbr</th>\n",
       "      <th>play_id</th>\n",
       "      <th>play_description</th>\n",
       "      <th>quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>team_coverage_type</th>\n",
       "      <th>penalty_yards</th>\n",
       "      <th>pre_penalty_yards_gained</th>\n",
       "      <th>yards_gained</th>\n",
       "      <th>expected_points</th>\n",
       "      <th>expected_points_added</th>\n",
       "      <th>pre_snap_home_team_win_probability</th>\n",
       "      <th>pre_snap_visitor_team_win_probability</th>\n",
       "      <th>home_team_win_probability_added</th>\n",
       "      <th>visitor_team_win_probility_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>09/07/2023</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>KC</td>\n",
       "      <td>DET</td>\n",
       "      <td>3461</td>\n",
       "      <td>(10:46) (Shotgun) J.Goff pass deep left to J.R...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>COVER_2_ZONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.664416</td>\n",
       "      <td>2.945847</td>\n",
       "      <td>0.834296</td>\n",
       "      <td>0.165704</td>\n",
       "      <td>-0.081149</td>\n",
       "      <td>0.081149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>09/07/2023</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>KC</td>\n",
       "      <td>DET</td>\n",
       "      <td>461</td>\n",
       "      <td>(7:30) J.Goff pass short right to J.Reynolds t...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>COVER_6_ZONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>1.926131</td>\n",
       "      <td>1.345633</td>\n",
       "      <td>0.544618</td>\n",
       "      <td>0.455382</td>\n",
       "      <td>-0.029415</td>\n",
       "      <td>0.029415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>09/07/2023</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>KC</td>\n",
       "      <td>DET</td>\n",
       "      <td>1940</td>\n",
       "      <td>(:09) (Shotgun) J.Goff pass incomplete deep ri...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>COVER_2_ZONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281891</td>\n",
       "      <td>-0.081964</td>\n",
       "      <td>0.771994</td>\n",
       "      <td>0.228006</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>09/07/2023</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>KC</td>\n",
       "      <td>DET</td>\n",
       "      <td>1711</td>\n",
       "      <td>(:45) (No Huddle, Shotgun) P.Mahomes pass deep...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>COVER_2_ZONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>3.452352</td>\n",
       "      <td>2.342947</td>\n",
       "      <td>0.663187</td>\n",
       "      <td>0.336813</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>-0.041843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>09/07/2023</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>KC</td>\n",
       "      <td>DET</td>\n",
       "      <td>1588</td>\n",
       "      <td>(1:54) (Shotgun) P.Mahomes pass incomplete dee...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>COVER_4_ZONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.921525</td>\n",
       "      <td>-0.324035</td>\n",
       "      <td>0.615035</td>\n",
       "      <td>0.384965</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.000061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id  season  week   game_date game_time_eastern home_team_abbr  \\\n",
       "0  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
       "1  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
       "2  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
       "3  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
       "4  2023090700    2023     1  09/07/2023          20:20:00             KC   \n",
       "\n",
       "  visitor_team_abbr  play_id  \\\n",
       "0               DET     3461   \n",
       "1               DET      461   \n",
       "2               DET     1940   \n",
       "3               DET     1711   \n",
       "4               DET     1588   \n",
       "\n",
       "                                    play_description  quarter  ...  \\\n",
       "0  (10:46) (Shotgun) J.Goff pass deep left to J.R...        4  ...   \n",
       "1  (7:30) J.Goff pass short right to J.Reynolds t...        1  ...   \n",
       "2  (:09) (Shotgun) J.Goff pass incomplete deep ri...        2  ...   \n",
       "3  (:45) (No Huddle, Shotgun) P.Mahomes pass deep...        2  ...   \n",
       "4  (1:54) (Shotgun) P.Mahomes pass incomplete dee...        2  ...   \n",
       "\n",
       "  team_coverage_type  penalty_yards  pre_penalty_yards_gained yards_gained  \\\n",
       "0       COVER_2_ZONE            NaN                        18           18   \n",
       "1       COVER_6_ZONE            NaN                        21           21   \n",
       "2       COVER_2_ZONE            NaN                         0            0   \n",
       "3       COVER_2_ZONE            NaN                        26           26   \n",
       "4       COVER_4_ZONE            NaN                         0            0   \n",
       "\n",
       "  expected_points expected_points_added  pre_snap_home_team_win_probability  \\\n",
       "0       -0.664416              2.945847                            0.834296   \n",
       "1        1.926131              1.345633                            0.544618   \n",
       "2        0.281891             -0.081964                            0.771994   \n",
       "3        3.452352              2.342947                            0.663187   \n",
       "4        1.921525             -0.324035                            0.615035   \n",
       "\n",
       "   pre_snap_visitor_team_win_probability  home_team_win_probability_added  \\\n",
       "0                               0.165704                        -0.081149   \n",
       "1                               0.455382                        -0.029415   \n",
       "2                               0.228006                         0.000791   \n",
       "3                               0.336813                         0.041843   \n",
       "4                               0.384965                         0.000061   \n",
       "\n",
       "  visitor_team_win_probility_added  \n",
       "0                         0.081149  \n",
       "1                         0.029415  \n",
       "2                        -0.000791  \n",
       "3                        -0.041843  \n",
       "4                        -0.000061  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---STEP 3: Let's go get the supplementary data---# \n",
    "\n",
    "# This block loads the Big Data Bowl supplementary data file from your Downloads folder.\n",
    "# It works for either CSV or Parquet formats and automatically adjusts based on the file type.\n",
    "\n",
    "# Import required Python libraries.\n",
    "\n",
    "from pathlib import Path    # Modern way to handle file paths (works on Windows/Mac/Linux)\n",
    "import pandas as pd         # Pandas is used to load and manipulate data tables\n",
    "\n",
    "\n",
    "# Define where the file is stored on your computer.\n",
    "\n",
    "# Path.home() → gives you your user’s home directory (e.g., C:\\Users\\<yourname>\\ on Windows)\n",
    "# / \"Downloads\" → navigates into your Downloads folder\n",
    "# / \"supplementary_data.csv\" → adds the actual filename\n",
    "# If your file has a different name (e.g., supplementary_data_week1.csv), change it here.\n",
    "\n",
    "supp_path = Path.home() / \"Downloads\" / \"supplementary_data.csv\"\n",
    "\n",
    "# Load the data based on its file type.\n",
    "\n",
    "# The .suffix attribute extracts the file extension (e.g., \".csv\", \".parquet\", \".xlsx\", etc.)\n",
    "# The code checks which kind of file it is and chooses the right pandas reader.\n",
    "\n",
    "if supp_path.suffix == \".csv\":\n",
    "    supp = pd.read_csv(supp_path)          # loads a comma-separated text file\n",
    "elif supp_path.suffix == \".parquet\":\n",
    "    supp = pd.read_parquet(supp_path)      # loads a Parquet file (common for large datasets)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file type: {supp_path.suffix}\")  # stops if unknown file type\n",
    "\n",
    "# Preview the first few rows of the dataset.\n",
    "\n",
    "# head() prints the first five rows so you can verify it loaded correctly.\n",
    "# It’s a quick sanity check before merging or analyzing the data.\n",
    "\n",
    "#Filter to Week 1 and make an explicit COPY \n",
    "supp_week1 = supp.loc[supp[\"week\"] == 1].copy()\n",
    "supp_week1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2cd1ed-8957-4f74-94dc-11f44e7d1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 4: Standardize data types for looking them up later---# \n",
    "\n",
    "# This step ensures your joins and merges across datasets (input, output, supplementary)\n",
    "# will work reliably and not break due to mismatched data types.\n",
    "\n",
    "# Loop through each of the main dataframes.\n",
    "\n",
    "# We have three key datasets:\n",
    "#   - input_df : tracking data BEFORE the throw\n",
    "#   - output_df : tracking data AFTER the throw\n",
    "#   - supp_week1 : play-level metadata (pass results, yards, coverage, etc.)\n",
    "#\n",
    "# This loop runs the same cleanup on each one.\n",
    "\n",
    "for df in [input_df, output_df, supp_week1]:\n",
    "    \n",
    "    # For each dataset, check for key columns: game_id, play_id\n",
    "   \n",
    "    # These columns identify unique plays and are critical for merges later.\n",
    "    # Some files might be missing one of them, so we check \"if k in df.columns\" first.\n",
    "\n",
    "    for k in [\"game_id\", \"play_id\"]:\n",
    "        if k in df.columns:\n",
    "\n",
    "            # Convert the column to a numeric type (Int64)\n",
    "          \n",
    "            # pd.to_numeric(..., errors=\"coerce\") forces everything to numeric;\n",
    "            # any invalid values become NaN instead of breaking.\n",
    "            # .astype(\"Int64\") ensures a consistent integer type that supports NaN.\n",
    "            #\n",
    "            # This avoids common merge issues where one dataframe has strings (\"2023090700\")\n",
    "            # and another has integers (2023090700).\n",
    "\n",
    "            df.loc[:, k] = pd.to_numeric(df[k], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# ✅ At this point:\n",
    "# All \"game_id\" and \"play_id\" columns across input_df, output_df, and supp_week1\n",
    "# are now numeric and standardized (safe for merging).\n",
    "\n",
    "# Extract a reference table of player metadata from input_df.\n",
    "\n",
    "# The input data contains static information about each player on a play,\n",
    "# such as which side they’re on (Offense/Defense), their role (Targeted Receiver, Passer, etc.),\n",
    "# and their name.\n",
    "#\n",
    "# We'll keep just these identifiers for easy merging later when analyzing output_df.\n",
    "\n",
    "roles = (\n",
    "    input_df[[\"game_id\", \"play_id\", \"nfl_id\", \"player_side\", \"player_role\", \"player_name\"]]\n",
    "    .drop_duplicates()  # removes duplicate rows so we have one record per player per play\n",
    ")\n",
    "\n",
    "# roles now acts like a lookup table:\n",
    "# You can merge it with output_df to know each player's role and side during post-throw analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae5663db-c336-4a45-b175-54f3d320afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 5: Let's dig in on each pass play---#\n",
    "\n",
    "# Create play-level reference points for passing plays from the input tracking data:\n",
    "# (a) where the quarterback threw from,\n",
    "# (b) who the intended receiver was,\n",
    "# (c) where that receiver was positioned at the throw,\n",
    "# (d) where the ball was expected to land.\n",
    "# These features let us later connect spatial data to outcomes (caught vs. not caught).\n",
    "\n",
    "# (a) THROW SNAPSHOT → last frame before the ball is thrown for the passer\n",
    "\n",
    "qb_throw = (\n",
    "    input_df.loc[input_df[\"player_role\"] == \"Passer\"]              # only quarterback rows\n",
    "            .sort_values([\"game_id\",\"play_id\",\"frame_id\"])         # order frames chronologically\n",
    "            .groupby([\"game_id\",\"play_id\"], as_index=False)        # group by unique play\n",
    "            .tail(1)[[\"game_id\",\"play_id\",\"nfl_id\",\"x\",\"y\"]]       # keep the last frame (throw moment)\n",
    "            .rename(columns={\"nfl_id\":\"passer_nfl_id\",             # rename columns for clarity\n",
    "                             \"x\":\"throw_x\",\"y\":\"throw_y\"})\n",
    ")\n",
    "# → qb_throw now holds each play’s QB location (x, y) at the exact throw frame.\n",
    "\n",
    "\n",
    "\n",
    "# (b) TARGETED RECEIVER ID → identify who the pass was intended for\n",
    "\n",
    "target_rec = (\n",
    "    input_df.loc[input_df[\"player_role\"] == \"Targeted Receiver\",   # filter to intended receivers\n",
    "                 [\"game_id\",\"play_id\",\"nfl_id\"]]                   # keep identifiers only\n",
    "            .drop_duplicates([\"game_id\",\"play_id\"])                # ensure one receiver per play\n",
    "            .rename(columns={\"nfl_id\":\"target_nfl_id\"})            # rename for clarity\n",
    ")\n",
    "# → target_rec is a simple lookup table linking each play to its targeted receiver’s nfl_id.\n",
    "\n",
    "\n",
    "# (c) RECEIVER SNAPSHOT AT THROW → where the target receiver was pre-throw\n",
    "\n",
    "rec_at_throw = (\n",
    "    input_df.loc[input_df[\"player_role\"] == \"Targeted Receiver\"]   # receiver’s tracking data\n",
    "            .sort_values([\"game_id\",\"play_id\",\"frame_id\"])         # order frames chronologically\n",
    "            .groupby([\"game_id\",\"play_id\"], as_index=False)\n",
    "            .tail(1)[[\"game_id\",\"play_id\",\"nfl_id\",\"x\",\"y\",\"s\",\"a\",\"dir\"]]  # last frame before throw\n",
    "            .rename(columns={\"nfl_id\":\"target_nfl_id\",             # rename for clarity and joinability\n",
    "                             \"x\":\"rec_throw_x\",\"y\":\"rec_throw_y\",\n",
    "                             \"s\":\"rec_throw_s\",\"a\":\"rec_throw_a\",\"dir\":\"rec_throw_dir\"})\n",
    ")\n",
    "# → rec_at_throw adds spatial (x,y) and movement features (speed, acceleration, direction)\n",
    "#   for the targeted receiver at the moment the ball leaves the QB’s hand.\n",
    "\n",
    "\n",
    "# (d) BALL LANDING LOCATION → where the ball is expected to land\n",
    "\n",
    "ball_land = (\n",
    "    input_df[[\"game_id\",\"play_id\",\"ball_land_x\",\"ball_land_y\"]]    # select landing coordinates\n",
    "             .dropna(subset=[\"ball_land_x\",\"ball_land_y\"])         # remove rows missing landing data\n",
    "             .drop_duplicates([\"game_id\",\"play_id\"])               # one row per play\n",
    ")\n",
    "#   ball_land gives one landing coordinate per play, used to compare with receiver position\n",
    "#   and later evaluate accuracy or completion probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a660af5b-a08e-4514-8ac3-eabf26aaa2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 6: Extract key outcome-level metadata for each play---#\n",
    "\n",
    "# We'll keep only the columns that describe *what happened* on the play, not the tracking details.\n",
    "\n",
    "# Select the outcome-level columns from supp_week1\n",
    "\n",
    "# supp_week1 is your Week 1 version of the supplementary file, one row per pass play.\n",
    "# Columns include contextual and result information (pass result, yards gained, EPA, etc.).\n",
    "\n",
    "play_meta = supp_week1[\n",
    "    [\"game_id\",                 # unique game identifier\n",
    "     \"play_id\",                 # unique play identifier (within each game)\n",
    "     \"pass_result\",             # categorical outcome: 'C' (complete), 'I' (incomplete), 'IN' (interception), etc.\n",
    "     \"yards_gained\",            # numeric measure of play outcome in yards\n",
    "     \"expected_points_added\"]   # EPA: expected change in scoring probability due to the play\n",
    "]\n",
    "# Result:\n",
    "\n",
    "# play_meta is now a compact DataFrame containing one record per passing play\n",
    "# with the most important *result* variables.\n",
    "# This smaller table can be merged onto your tracking data (by game_id + play_id)\n",
    "# to attach outcome labels to each play.\n",
    "\n",
    "# Example shape and columns:\n",
    "# >>> play_meta.head()\n",
    "#     game_id   play_id pass_result  yards_gained  expected_points_added\n",
    "# 0  2023090700     3461          C            18               2.945847\n",
    "# 1  2023090700      461          C            21               1.345633\n",
    "# 2  2023090700     1940          I             0              -0.081964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23d5f985-2664-482d-81fa-7b1ef977c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 7: Tag each player’s tracking data with side/role, then isolate post-throw trajectories for the targeted receiver and all defenders---#\n",
    "\n",
    "# Combine post-throw tracking data with player metadata (offense/defense, roles),\n",
    "# then isolate trajectories for (a) the targeted receiver and (b) all defenders.\n",
    "# These will be used to measure distances and movement patterns after the ball is thrown.\n",
    "\n",
    "# (1) Annotate output rows with player side and role\n",
    "\n",
    "out_tagged = output_df.merge(\n",
    "    roles,                              # lookup table from input_df with player_side, player_role, and player_name\n",
    "    on=[\"game_id\",\"play_id\",\"nfl_id\"],  # join on the shared identifiers\n",
    "    how=\"left\",                         # keep all tracking rows from output_df\n",
    "    validate=\"many_to_one\"              # ensures many tracking frames link to one player-role record\n",
    ")\n",
    "# Result: each row in output_df now has added columns like:\n",
    "#     player_side ('Offense' or 'Defense')\n",
    "#     player_role ('Targeted Receiver', 'Passer', etc.)\n",
    "# This provides context for interpreting movements after the throw.\n",
    "\n",
    "# (2) Extract the targeted receiver's trajectory (after throw)\n",
    "\n",
    "receiver_traj = (\n",
    "    out_tagged\n",
    "        .merge(target_rec, on=[\"game_id\",\"play_id\"], how=\"inner\")  # attach target_nfl_id for each play\n",
    "        .query(\"nfl_id == target_nfl_id\")                          # keep only rows for that targeted player\n",
    "        [[\"game_id\",\"play_id\",\"frame_id\",\"nfl_id\",\"x\",\"y\"]]         # keep essential tracking columns\n",
    "        .rename(columns={\"x\":\"rec_x\",\"y\":\"rec_y\"})                  # rename for clarity (receiver coordinates)\n",
    ")\n",
    "# Result: receiver_traj contains x/y positions of the targeted receiver across frames\n",
    "# after the throw — useful for modeling the receiver’s movement toward the catch point.\n",
    "\n",
    "# (3) Extract all defenders’ trajectories\n",
    "\n",
    "defenders_traj = (\n",
    "    out_tagged\n",
    "        .query(\"player_side == 'Defense'\")                         # filter to defensive players\n",
    "        [[\"game_id\",\"play_id\",\"frame_id\",\"nfl_id\",\"x\",\"y\"]]         # retain tracking identifiers and coordinates\n",
    "        .rename(columns={\"x\":\"def_x\",\"y\":\"def_y\",\"nfl_id\":\"def_nfl_id\"})  # rename for clarity\n",
    ")\n",
    "# Result: defenders_traj contains x/y positions for every defender at each frame\n",
    "# after the throw — used to calculate nearest-defender distances to the receiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fde16e4-ac47-424e-aabc-12a54f5b26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 8: Build play-level anchors from pre-throw tracking---#\n",
    "\n",
    "# (a) QB throw location, (b) targeted receiver ID,\n",
    "# (c) receiver’s location/motion at throw, (d) ball landing spot.\n",
    "\n",
    "# (a) THROW SNAPSHOT — QB’s last pre-throw frame (the release moment)\n",
    "qb_throw = (\n",
    "    input_df.loc[input_df[\"player_role\"] == \"Passer\"]              # keep only QB rows\n",
    "            .sort_values([\"game_id\", \"play_id\", \"frame_id\"])       # order frames within each play\n",
    "            .groupby([\"game_id\", \"play_id\"], as_index=False)       # group per play\n",
    "            .tail(1)                                               # take the last pre-throw frame\n",
    "            [[\"game_id\", \"play_id\", \"nfl_id\", \"x\", \"y\"]]           # keep IDs + position\n",
    "            .rename(columns={                                       # rename for clarity\n",
    "                \"nfl_id\": \"passer_nfl_id\",\n",
    "                \"x\": \"throw_x\",\n",
    "                \"y\": \"throw_y\"\n",
    "            })\n",
    ")\n",
    "# Result: one row per play with QB’s (x,y) at the throw.\n",
    "\n",
    "# (b) TARGETED RECEIVER ID — who the pass was intended for (one per play)\n",
    "target_rec = (\n",
    "    input_df.loc[input_df[\"player_role\"] == \"Targeted Receiver\",   # intended receiver rows\n",
    "                 [\"game_id\", \"play_id\", \"nfl_id\"]]\n",
    "            .drop_duplicates([\"game_id\", \"play_id\"])                # ensure 1 receiver per play\n",
    "            .rename(columns={\"nfl_id\": \"target_nfl_id\"})            # clearer name for later joins\n",
    ")\n",
    "# Result: lookup table (game_id, play_id) -> target_nfl_id.\n",
    "\n",
    "# (c) RECEIVER SNAPSHOT AT THROW — target’s last pre-throw frame (position & motion)\n",
    "rec_at_throw = (\n",
    "    input_df.loc[input_df[\"player_role\"] == \"Targeted Receiver\"]   # target receiver rows\n",
    "            .sort_values([\"game_id\", \"play_id\", \"frame_id\"])       # order frames\n",
    "            .groupby([\"game_id\", \"play_id\"], as_index=False)\n",
    "            .tail(1)                                               # last pre-throw frame for target\n",
    "            [[\"game_id\",\"play_id\",\"nfl_id\",\"x\",\"y\",\"s\",\"a\",\"dir\"]] # pos + kinematics\n",
    "            .rename(columns={\n",
    "                \"nfl_id\": \"target_nfl_id\",\n",
    "                \"x\": \"rec_throw_x\",\n",
    "                \"y\": \"rec_throw_y\",\n",
    "                \"s\": \"rec_throw_s\",\n",
    "                \"a\": \"rec_throw_a\",\n",
    "                \"dir\": \"rec_throw_dir\"\n",
    "            })\n",
    ")\n",
    "# Result: target’s (x,y,s,a,dir) at throw time per play.\n",
    "\n",
    "# (d) BALL LANDING — expected landing coordinates (one per play, first non-null)\n",
    "ball_land = (\n",
    "    input_df[[\"game_id\", \"play_id\", \"ball_land_x\", \"ball_land_y\"]] # select landing cols\n",
    "            .dropna(subset=[\"ball_land_x\", \"ball_land_y\"])         # require both coords\n",
    "            .drop_duplicates([\"game_id\", \"play_id\"])               # one landing per play\n",
    ")\n",
    "# Result: (game_id, play_id) -> ball_land_x, ball_land_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cac1207-dcef-4fbc-9d81-01a1b9fc67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 9 Set up distance calculations---#\n",
    "\n",
    "# Combine post-throw tracking data with player metadata, then separate trajectories for\n",
    "# (a) the targeted receiver and (b) all defenders. This sets up distance calculations later.\n",
    "\n",
    "# (1) Annotate each row of output_df with player side and role\n",
    "out_tagged = output_df.merge(\n",
    "    roles,                              # lookup of player info from input_df\n",
    "    on=[\"game_id\",\"play_id\",\"nfl_id\"],  # join keys for matching records\n",
    "    how=\"left\",                         # keep all tracking rows from output_df\n",
    "    validate=\"many_to_one\"              # ensures each player maps to one role record\n",
    ")\n",
    "#  out_tagged = output_df + context columns like player_side and player_role\n",
    "\n",
    "# (2) Receiver trajectory after throw (target only)\n",
    "receiver_traj = (\n",
    "    out_tagged\n",
    "        .merge(target_rec, on=[\"game_id\",\"play_id\"], how=\"inner\")  # adds target_nfl_id per play\n",
    "        .query(\"nfl_id == target_nfl_id\")                          # keeps only the targeted receiver\n",
    "        [[\"game_id\",\"play_id\",\"frame_id\",\"nfl_id\",\"x\",\"y\"]]         # select position data\n",
    "        .rename(columns={\"x\":\"rec_x\",\"y\":\"rec_y\"})                  # rename for clarity\n",
    ")\n",
    "#  receiver_traj holds the x/y positions of the targeted receiver across all post-throw frames.\n",
    "\n",
    "# (3) Defenders’ trajectories (all defenders)\n",
    "defenders_traj = (\n",
    "    out_tagged\n",
    "        .query(\"player_side == 'Defense'\")                         # filter to defensive players\n",
    "        [[\"game_id\",\"play_id\",\"frame_id\",\"nfl_id\",\"x\",\"y\"]]         # select core tracking columns\n",
    "        .rename(columns={\"x\":\"def_x\",\"y\":\"def_y\",\"nfl_id\":\"def_nfl_id\"})\n",
    ")\n",
    "#  defenders_traj holds x/y positions for every defensive player per frame, ready to compare to receiver_traj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e95cb08-78de-4f19-b596-d356839fd43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 10 Find the nearest defender---#\n",
    "\n",
    "# Pair each receiver frame with all defenders in the same frame ---\n",
    "# This creates all possible defender–receiver pairs for each frame of each play.\n",
    "pairwise = defenders_traj.merge(\n",
    "    receiver_traj,                      # receiver trajectory (target receiver only)\n",
    "    on=[\"game_id\", \"play_id\", \"frame_id\"],  # join on game, play, and frame\n",
    "    how=\"inner\"                         # keep only frames that appear in both datasets\n",
    ")\n",
    "\n",
    "# Calculate Euclidean distance between defender and receiver ---\n",
    "# np.hypot computes sqrt(dx**2 + dy**2) safely and efficiently.\n",
    "pairwise[\"dist_to_receiver\"] = np.hypot(\n",
    "    pairwise[\"def_x\"] - pairwise[\"rec_x\"],  # horizontal distance difference\n",
    "    pairwise[\"def_y\"] - pairwise[\"rec_y\"]   # vertical distance difference\n",
    ")\n",
    "\n",
    "# Identify the nearest defender per frame ---\n",
    "# Group by frame to find the minimum distance (closest defender) for that receiver.\n",
    "nearest_per_frame = (\n",
    "    pairwise\n",
    "    .groupby([\"game_id\", \"play_id\", \"frame_id\"], as_index=False)\n",
    "    .agg(min_def_dist=(\"dist_to_receiver\", \"min\"))  # get smallest defender distance\n",
    ")\n",
    "\n",
    "# nearest_per_frame now contains:\n",
    "# one row per frame with the minimum distance between the receiver and the closest defender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e96f68f-661c-464a-848d-8f011b852296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 11: Get the closest defender at the final frame---#\n",
    "\n",
    "# For each play, find the maximum frame_id (the final frame)\n",
    "last_frames = (\n",
    "    receiver_traj\n",
    "    .groupby([\"game_id\", \"play_id\"], as_index=False)[\"frame_id\"]\n",
    "    .max()\n",
    "    .rename(columns={\"frame_id\": \"last_output_frame\"})\n",
    ")\n",
    "\n",
    "# Get the closest defender distance (min_def_dist) at the *final frame* of each play.\n",
    "final_min = (\n",
    "    nearest_per_frame\n",
    "    .merge(\n",
    "        last_frames,                             # contains last frame info per play (with last_output_frame)\n",
    "        on=[\"game_id\", \"play_id\"],               # join by game and play IDs\n",
    "        how=\"inner\"                              # only keep plays that appear in both\n",
    "    )\n",
    "    .query(\"frame_id == last_output_frame\")      # keep only the *last frame* for each play\n",
    "    .rename(columns={\"min_def_dist\": \"final_min_def_dist\"})  # rename for clarity\n",
    "    [[\"game_id\", \"play_id\", \"final_min_def_dist\"]]            # keep only relevant columns\n",
    ")\n",
    "\n",
    "# Compute the *average* closest-defender distance throughout each play.\n",
    "mean_min = (\n",
    "    nearest_per_frame\n",
    "    .groupby([\"game_id\", \"play_id\"], as_index=False)[\"min_def_dist\"]\n",
    "    .mean()                                     # mean distance per play across all frames\n",
    "    .rename(columns={\"min_def_dist\": \"mean_min_def_dist\"})   # rename for clarity\n",
    ")\n",
    "\n",
    "\n",
    "# Find how many frames (moments) each play has — useful for weighting or pacing.\n",
    "frame_count = (\n",
    "    receiver_traj\n",
    "    .groupby([\"game_id\", \"play_id\"], as_index=False)[\"frame_id\"]\n",
    "    .nunique()                                  # number of unique frames for that receiver in each play\n",
    "    .rename(columns={\"frame_id\": \"n_output_frames\"})          # rename for clarity\n",
    ")\n",
    "\n",
    "# Combine all summary metrics into one table \n",
    "# Merge mean distance, final-frame distance, and frame count into a single DataFrame.\n",
    "play_dist_summ = (\n",
    "    mean_min\n",
    "    .merge(final_min, on=[\"game_id\", \"play_id\"], how=\"left\")  # add final-frame min distance\n",
    "    .merge(frame_count, on=[\"game_id\", \"play_id\"], how=\"left\")# add frame count per play\n",
    ")\n",
    "\n",
    "# play_dist_summ now includes:\n",
    "#  - mean_min_def_dist: average closest-defender distance across frames\n",
    "#  - final_min_def_dist: distance at the last frame of the play\n",
    "#  - n_output_frames: total frames in that play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46303849-46a6-42ac-b237-ee59aa95f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---STEP 11: Combine into 1 Table---#\n",
    "\n",
    "# Merge coverage metrics (distances) with metadata and event-level info.\n",
    "play_level = (\n",
    "    play_dist_summ\n",
    "    .merge(play_meta, on=[\"game_id\", \"play_id\"], how=\"left\")      # adds play outcomes (e.g., result, yards gained)\n",
    "    .merge(qb_throw, on=[\"game_id\", \"play_id\"], how=\"left\")       # adds QB throw location (x, y at release)\n",
    "    .merge(rec_at_throw, on=[\"game_id\", \"play_id\"], how=\"left\")   # adds receiver location at time of throw\n",
    "    .merge(ball_land, on=[\"game_id\", \"play_id\"], how=\"left\")      # adds ball landing point (where pass ends)\n",
    "    .merge(target_rec, on=[\"game_id\", \"play_id\"], how=\"left\")     # adds receiver target ID or metadata\n",
    ")\n",
    "\n",
    "# Goal: Measure straight-line distance between the QB's throw point and where the ball lands.\n",
    "# np.hypot(dx, dy) computes the Euclidean distance sqrt(dx^2 + dy^2).\n",
    "play_level[\"air_yards_est\"] = np.hypot(\n",
    "    play_level[\"ball_land_x\"] - play_level[\"throw_x\"],   # horizontal distance (x-axis)\n",
    "    play_level[\"ball_land_y\"] - play_level[\"throw_y\"],   # vertical distance (y-axis)\n",
    ")\n",
    "\n",
    "# play_level now contains:\n",
    "#   • mean_min_def_dist : average closest-defender distance per play\n",
    "#   • final_min_def_dist : final-frame defender distance\n",
    "#   • n_output_frames : number of frames analyzed\n",
    "#   • play_meta fields :  play outcomes (yards, completion, etc.)\n",
    "#   • qb_throw, rec_at_throw, ball_land : spatial event coordinates\n",
    "#   • air_yards_est : estimated air yards from throw to landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74dd94bd-ffb2-473f-a342-7d75f8329257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       final_min_def_dist                                                    \\\n",
      "                    count   mean    std    min    25%    50%    75%     max   \n",
      "caught                                                                        \n",
      "False               251.0  2.079  1.942  0.020  0.851  1.386  2.623  14.281   \n",
      "True                502.0  3.591  2.413  0.261  1.812  3.087  4.686  14.830   \n",
      "\n",
      "       mean_min_def_dist         ... air_yards_est         n_output_frames  \\\n",
      "                   count   mean  ...           75%     max           count   \n",
      "caught                           ...                                         \n",
      "False              251.0  2.608  ...        31.598  61.840           251.0   \n",
      "True               502.0  4.219  ...        23.764  51.271           502.0   \n",
      "\n",
      "                                                    \n",
      "          mean    std  min  25%   50%    75%   max  \n",
      "caught                                              \n",
      "False   13.339  6.226  5.0  9.0  11.0  16.00  34.0  \n",
      "True    10.378  5.072  5.0  8.0   9.0  11.75  94.0  \n",
      "\n",
      "[2 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "#---STEP 12: Results Summary---# \n",
    "\n",
    "summary = (\n",
    "    play_level\n",
    "    # Create a new Boolean column 'caught' \n",
    "    # .assign() adds or modifies columns; lambda d: d[...] references the DataFrame itself.\n",
    "    # .eq(\"C\") checks whether 'pass_result' equals \"C\" (caught), returning True/False.\n",
    "    .assign(caught=lambda d: d[\"pass_result\"].eq(\"C\"))\n",
    "\n",
    "    # Group plays by whether the pass was caught \n",
    "    # This separates plays into caught (True) and not caught (False) groups.\n",
    "    .groupby(\"caught\")[[\"final_min_def_dist\", \"mean_min_def_dist\", \"air_yards_est\", \"n_output_frames\"]]\n",
    "\n",
    "    # Describe each group statistically\n",
    "    # .describe() computes count, mean, std, min, quartiles, and max for each numeric column.\n",
    "    .describe()\n",
    "    .round(3)  # round all numeric results to 3 decimal places for readability\n",
    ")\n",
    "\n",
    "# --- Display the results ---\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afcb91-81e5-4b14-8918-91090e62ba17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
